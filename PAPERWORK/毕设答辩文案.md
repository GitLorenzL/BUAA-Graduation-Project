# 毕设答辩

老师们早上好，我今天主要从四个方面来介绍我的毕业设计。（翻）



首先是此次研究的大致研究内容。（翻）



我在这次研究中完成了对场景与目标浏览、目标选择和对象操纵的设计与实现；这三个核心部分构成了完整交互系统。另外，我们也针对头眼协同交互提出了几种信号处理方法，以确保一个更加自然而且低负担的操纵流程。同时，我也完成了两个先导实验和两个用户实验，以尽可能全面地评估该交互系统。（翻）



接下来我将详细介绍一下我的技术路线。（翻）



首先，我们针对整个交互系统引入了一个有限状态机，有利于维护系统稳定性。它明确了状态转换，能够有效避免意外行为，并且强制规定了合法的状态转换，保持系统一致性，提供了可控的系统响应方式。同时，在开发过程中，状态机的引入也方便调试和排查问题。（翻）



另外，我们基于该状态机提出了一个“四叶草”模式选择菜单，用户仅需要眼动即可快速、便捷地在各状态中切换，解决了当下对象操纵研究中存在的连续性问题，构建了一个完整的闭环操纵流程。（翻）



除此之外，眼动操纵的最大难点即眼动信号不稳定，存在非常严重的脉冲信号干扰。因此，这也是我们的研究重点之一。我们主要通过一下几个方法来对抗不稳定性以及干扰。首先是一个滤波算法；我们采用了中位值平均滤波算法，并且针对系统对其进行了调整；该算法的伪代码在论文的3.5.1-眼动信号滤波算法中。中位值平均滤波算法是一种常用的数字信号处理方法，它结合了中位值滤波和算术平 均滤波的优点，能有效地抑制脉冲噪声和周期性干扰，提高信号的平滑度和稳定性。

该滤波算法的效果如图所示，可见其真实性、信号特征和平滑度都是很理想的，并且延迟也不高。（翻）



其次，我们引入了一个感知阈值，我们会忽略阈值以内的眼动信号变化，主要为了避免因过度灵敏而产生的误操作。（翻）



最后，我们引入了一个优化方程，用来优化对注视停留的检测。引入该优化的原因是在目标选择时，单纯依靠眼动或者头动的射线广播来选择物体是不理想、不够自然的，会引入不必要的使用负担。同时，这个优化也可以对抗干扰而触发更加精确的动作。我们将在之后的一个先导实验中证明该优化的必要性（翻）



眼动操纵的另一大难点即眼动范围极小。所以，我们引入了一个眼动信号增强函数。这个增强函数的效果是，让用户在小幅度动作时可以对对象进行微调，在大幅度动作时可以让对象作快速动作。（翻）



接下来我将大致介绍一下该对象操纵交互系统的pipeline，首先系统处于初始状态IDLE态，此时用户可以通过头动向前射线指向目标物体，之后通过发出确认信号，即快速两次眨眼以选中该物体作为目标对象；选中对象之后，系统进入OBJECT_SELECTED状态，此时用户界面中心会生成一个“四叶草”操纵模式选择菜单，在菜单中的对应区域驻留凝视一定时间，到确认进度盘变满后则可进入对应的操纵模式，在此以缩放为例。进入缩放模式后，状态转移为OBJECT_RESCALING，在具体的操纵完成后，用户可以随时通过再次发出确认信号以确认操纵结果并返回到OBJECT_SELECTED状态。此时用户可以继续选择对该对象进行其他操纵，也可以通过凝视选择“CANCEL”退回到 IDLE状态。接下来我将按照实际的操纵步骤更加详细地介绍交互的每一个环节。（翻）



首先用户以单纯头动来浏览场景和目标（翻）



此时，如果头动的向前forward射线与某物体碰撞，则该物体高亮（翻）



如果这个高亮物体是目标对象，则快速两次眨眼以选择该物体进行操纵（翻）



此时，系统状态转移到OBJECT_SELECTED状态，同时在用户界面最顶层会出现一个操纵模式选择菜单以供用户选择进入某种操纵或者返回初始态（翻）



假设此时用户想要位移对象，用户只需要让眼动forward射线驻留在TRANSLATING上以进入对象位移操纵模式（翻）



此时，系统状态转移到OBJECT_TRANSLATING状态，用户这时可以通过具体的额眼动动作操纵对象。在这个例子中，假定用户想让对象右移，则只需要向右看；由于信号增强函数，其运动速度和眼动forward射线偏移程度正相关。（翻）



当用户操纵对象移动到目标位置后，只用快速眨眼两次以确认操纵结果（翻）



这时系统回到OBJECT-SELECTED状态，选择菜单再次出现。这时用户可以继续选择下一个操纵模式，也可以选择退回到初始态（翻）



在这里我们假定用户已经完成对这个物体的操纵，需要回到初始态浏览其他物体，则注视选择CANCEL以退回到IDLE状态（翻）



到这一步，一个完整的交互流程就结束了（翻）



对于具体的三种对象操纵，我们规定为如下交互行为。它们对应的数学表达式在论文中的3.4-对象操纵中可见。核心思想是尽量采用眼动，并且采取最为自然直观的交互方法。其中旋转、缩放和X-Y平面的位移完全采用眼动进行操纵，只有在Z轴纵深方向上的位移需要头动的辅助参与。（翻）



接下来我来介绍一下我的实验设计（翻）



首先是先导实验，也就是常说的pilot study；由于这部分在中期报告中已作出过详细的介绍，所以在此我们仅作简短的回顾。第一个先导实验是眼动确认信号的筛选。我们从最为常见且自然的两种主动眼动信号(单眼眨眼和快速两次眨眼)中确定一个最为高效并且带来最小使用压力的眼动确认信号。（翻）



每名参试者将使用不同的两个眼动确认信号分两次完成同样的一个任务。该任务内容是，在虚拟环境中会依次在随机时刻和随机位置出现 20 个小球，参试者需要使用当次实验规定的眼动信号选择以消灭它们。 （翻）



这是一次实验的实况录像，在界面中可见这次的眼动确认信号是快速两次眨眼。每个小球在上一个被销毁后随机出现，参试者需要尽快选择以消灭他们。（视频完翻）



在实验完成后，我们将针对NASA task load这一主观度量和任务完成时间、信号反馈精确系数两个客观度量评估实验结果。（翻）



这是我们对先导实验1的结果汇报；曼恩惠特尼U检验表示，三种度量全部有显著差异，而快速两次眨眼的均值更为理想，故可以确定为眼动确认信号。（翻）



第二个先导实验的目的是探究驻留检测优化的必要性。此次实验的设置和第一个先导实验几乎一致，只不过我们始终规定确认信号为快速两次眨眼。在实验完成后，每名参试者将分别针对两次任务完成一个NASA-TLX 任务负担表 （翻）



这是我们对先导实验2的结果汇报；检验表示引入和不引入优化在使用负担上有显著的差异，故我们有必要引入优化。（翻）



接下来是用户实验部分。为了消除偶然性、保证多样性，我们招募了 14 名参试者，并且尽可能确保男女比例相当。 用户实验1是针对单物体的单纯位移对接实验，我们复用了目前基于头眼协同的最优方法orthogaze的一个任务，并且将orthogaze作为一个baseline。该用户实验设计为：在一个2N为边长的立方体空间中，用户将完成16次正方体从初始位置到目标位置的对接。 （翻）



在开始实验之前，参试者将进行 10 次对接练习。在正式实验开始后，如果参试者在 30 秒内没有对齐立方体，则本次任务将被视为失败。

我们将从眩晕感、可用性和任务负担三个主观度量以及三个客观度量来评估每一个参试者的实验结果。

在客观度量中，成功率是针对每个参与者计算的，是成功任务的次数与所有任务次数的比率。这评估了操作物体的总体效率，因为要成功完成一个任务需要全面考虑准确性和速度。

完成时间在每个成功完成的任务中，完成时间将被记录;对于此项度量，我们不会将失败的任务纳入考虑。

最终距离仅针对失败的任务。最终距离是指在任务失败时刻白色立方体到目标位置的欧几里得距离;这反映了参试者在将物体移动到目标位置时相对于其初始位置的靠近或者远离程度。（翻）



这是一个用户实验1中一次任务的实况录像，也代表了一个完整的交互流程，其中用户的眼部动作实时反馈到视频左侧的虚拟人物形象上。同时，由于本次实验涉及需要头部辅助的纵深方向位移，我们会观察到头部摄像头的倾斜。（视频完翻）



这是我们对用户实验1的结果汇报，对应论文4.2.1节的表4.4。（翻）



结果表明我们的均值表现在各度量上皆优于OrthoGaze；而且根据One-way ANOVA方差分析，我们的方法和OrthoGaze在各度量上皆存在显著差异，所以我们可以得出结论：我们的方法在使用效率和用户体验上显著优于同类最优方法 OrthoGaze。（翻）



另外，我们单独考虑参试者的 VR 经验对完成时间带来的影响，以此来探究我们的方法是否易于学习。一个判断依据是如果我们的方法易于学习，那么VR经验的不同不会造成产出结果的显著差异。根据One-way ANOVA分析，三种 VR 经验对应的完成时间数据没有显著差异，所以我们也可以得出我们的方法具备高可学习性的结论。（翻）



接下来是我们的用户实验2。本实验为多物体操纵，并且保证涵盖位移、旋转和缩放，以全面评估该对象操纵系统。我们选择以目前基于手的两个方法作为对照方法，一个是变体最多的PRISM方法，一个是目前最优的Implicit Gaze方法。（翻）



参试者将被要求分别使用我们的方法和两个对照方法完成一个“积木”实验。在每次实验中，参试者需要尽快将右侧的积木通过位移、 旋转、缩放搭建为左侧的目标形状。每次实验有 60s 的完成时间；在这期间，系统实时计算积木与目标形状的相似度。（翻）



在实验完成时间内，一旦豪斯多夫距离小于某一阈值，则认定实验成功，记录完成时间，实验结束；若超出完成时间都还没有达到相似，则认定实验失败，实验结束并记录此时的豪斯多夫距离作为最终距离。全部参试者完成实验后，我们计算实验成功率，针对成功的实验统计完成时间，针对失败的实验统计最终距离，并最终以这三个客观度量评估实验结果。（翻）



这是一次成功实验的完整屏幕录像，也展示了我们的状态机和“四叶草”模式选择菜单的运作机制。同样地，用户的眼部动作也将实时反馈到视频左侧的虚拟人物形象上。（视频完翻）



这是我们对用户实验2的结果汇报，对应论文4.2.2节的表4.6。（翻）



接下来我们对实验数据进行分析。首先，针对完成时间这一度量，我们首先检验发现三组数据都符合正态分布，并且都通过方差齐性检测，所以我们可以使用One-way ANOVA进行方差分析。而One-way ANOVA检验表明三组数据中至少有两组存在显著差异，所以我们使用Tukey HSD事后检验，发现我们的方法和Implicit Gaze皆显著优于PRISM，同时，我们的方法和Implicit Gaze无显著差异。

针对成功率，我们的方法成功率高于PRISM，并且和基于手的最优方法成功率保持一致。最后，针对最终距离三种方法的最终距离无显著差异。（翻）



因此，考虑到目前对象操纵方法中最优的一类即基于手的方法，而PRISM是变体最多、最广泛使用的方法之一。我们可以得出结论：我们的方法不亚于任何基于手的方法，并且在效率上显著优于PRISM方法。（翻）



最后，我将对我的毕业设计工作作出总结和展望。（翻）



本次研究的主要贡献在于以下四点:

1. 提出了一个基于头眼协同的、完全无手干预的全面6DOF对象操纵方法流程 (pipeline)，并且显著优于当前同类方法;
2. 提出了一个“四叶草”模式选择菜单,解决了对象操纵研究的模式间切换问题, 构建了一个完整的闭环操纵流程;
3. 提出了一种眼动信号的滤波算法和一种头眼协同的凝视驻留点计算优化方程;
4. 提出了一种全面测试对象操纵的“积木”用户实验,有助于相关研究对其方法效果的定量测试。（翻）



同时，本次研究也存在三点局限性：

1. 我们对于该交互系统的预设为用户始终固定在一个位置进行操纵
2. 用户在使用眼动信号进行交互时难以做到随时观察对象的状态
3. 我们在目标对象选择时没有考虑遮挡问题（翻）



针对未来可能开展的工作，我们可以首先针对局限性进行完善，比如引入相对坐标系、设置定点虚拟摄像头、设置预选集等。除此之外，我们也可以创建并完善该对象操纵方法的API，允许更多的应用程序接入并使用该操纵方法，以促进更新与迭代，从而增强该操纵方法的功能和价值。（翻）



我的毕业设计工作汇报完毕，请老师们批评指正。